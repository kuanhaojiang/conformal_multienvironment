{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8635ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from matplotlib.pyplot import figure\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data can be downloaded at https://osf.io/tb8fx/\n",
    "df = pd.read_csv(\"combined\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a599103",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_plus(v, alpha):\n",
    "    n = v.shape[0]\n",
    "    r = (np.ceil((1-alpha)*(n+1)) - 1).astype(int)\n",
    "    if r == n:\n",
    "        return float(\"inf\")\n",
    "    return np.sort(v)[r]\n",
    "\n",
    "def q_minus(v, alpha):\n",
    "    n = v.shape[0]\n",
    "    r = (np.floor(alpha*(n+1)) - 1).astype(int)\n",
    "    if r == -1:\n",
    "        return -float(\"inf\")\n",
    "    return np.sort(v)[r]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584468d",
   "metadata": {},
   "source": [
    "# Split Conformal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_conformal(df_train, df_test, alpha_delta_list, train_ratio=0.6):        \n",
    "    train_idx = df_train[\"Electrode\"].unique()\n",
    "    fit_idx, residual_idx = train_test_split(train_idx, train_size=train_ratio)\n",
    "    \n",
    "    # df_fit is the data used to fit the models\n",
    "    df_fit = df_train[df_train.Electrode.isin(fit_idx)]\n",
    "    # df_fit is the data used to compute the residuals\n",
    "    df_residual = df_train[df_train.Electrode.isin(residual_idx)]\n",
    "\n",
    "    lin_model = get_model()\n",
    "    lin_model.fit(df_fit.drop(columns=[\"DA\", \"Electrode\"]), df_fit[\"DA\"])\n",
    "    \n",
    "    # compute residuals using the remaining training environments\n",
    "    training_residuals = {}\n",
    "    for i in residual_idx:\n",
    "        curr_df = df_residual[df_residual.Electrode == i]\n",
    "        residual = np.abs(curr_df[\"DA\"] - lin_model.predict(curr_df.drop(columns=[\"DA\", \"Electrode\"])))\n",
    "        training_residuals[i] = residual\n",
    "    \n",
    "    # compute the residual quantiles\n",
    "    q_dict = {}\n",
    "    for alpha, delta in alpha_delta_list:  \n",
    "        quantile_residuals = []\n",
    "        for i in residual_idx:\n",
    "            residual = training_residuals[i]\n",
    "            quantile_residuals.append(q_plus(residual, alpha))\n",
    "        quantile_residuals = np.array(quantile_residuals)\n",
    "        q_dict[(alpha, delta)] = q_plus(quantile_residuals, delta)\n",
    "\n",
    "    # this stores the total cardinality of constructed confidence sets\n",
    "    total_card_list = defaultdict(list)\n",
    "    # this stores the number of total covered samples\n",
    "    total_covered_list = defaultdict(list)\n",
    "    # this stores the number of total samples\n",
    "    total_count_list = defaultdict(list)\n",
    "    \n",
    "    test_idx = df_test[\"Electrode\"].unique()\n",
    "    for test_idx_num in test_idx:\n",
    "        curr_df = df_test[df_test.Electrode == test_idx_num]\n",
    "        y_pred = lin_model.predict(curr_df.drop(columns=[\"DA\", \"Electrode\"]))\n",
    "        y_true = curr_df[\"DA\"]\n",
    "\n",
    "        for alpha, delta in alpha_delta_list:\n",
    "            q = q_dict[(alpha, delta)]\n",
    "            hi, lo = y_pred + q, y_pred - q\n",
    "            hi[hi > 2000], hi[hi < 0] = 2000, 0\n",
    "            lo[lo > 2000], lo[lo < 0] = 2000, 0\n",
    "            \n",
    "            # set size\n",
    "            total_card_list[(alpha, delta)].append(np.sum(hi - lo))\n",
    "            # ratio of covered samples\n",
    "            total_covered_list[(alpha, delta)].\\\n",
    "            append(np.where(np.logical_and(y_true>=lo, y_true<=hi))[0].shape[0])\n",
    "            # number of total samples\n",
    "            total_count_list[(alpha, delta)].append(y_pred.shape[0])\n",
    "\n",
    "    results_dict = {}\n",
    "    for alpha, delta in alpha_delta_list:\n",
    "        curr_total_covered_list = np.array(total_covered_list[(alpha, delta)])\n",
    "        curr_total_card_list = np.array(total_card_list[(alpha, delta)])\n",
    "        curr_total_count_list = np.array(total_count_list[(alpha, delta)])\n",
    "\n",
    "        # compute empirical delta\n",
    "        emp_delta = np.mean(curr_total_covered_list >= np.ceil((curr_total_count_list + 1) * (1 - alpha)))\n",
    "        # compute average set size\n",
    "        emp_card = np.mean(curr_total_card_list / curr_total_count_list)\n",
    "        # compute empirical alpha\n",
    "        is_valid_coverage = (curr_total_covered_list >= (1-alpha)*(1+curr_total_count_list))\n",
    "        coverage_ratio = curr_total_covered_list / curr_total_count_list\n",
    "        emp_alpha = np.mean(coverage_ratio[is_valid_coverage])\n",
    "        \n",
    "        results_dict[(alpha, delta)] = (emp_delta, emp_alpha, emp_card)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5dd75",
   "metadata": {},
   "source": [
    "# Jackknife Conformal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jackknife_conformal(df_train, df_test, alpha_delta_list):\n",
    "    train_idx = df_train[\"Electrode\"].unique()\n",
    "    \n",
    "    # train the LOO models\n",
    "    models = []\n",
    "    for i in train_idx:\n",
    "        df_concate = df_train[df_train.Electrode != i]\n",
    "        LOO_model = get_model()\n",
    "        LOO_model.fit(df_concate.drop(columns=[\"DA\", \"Electrode\"]), df_concate[\"DA\"])\n",
    "        models.append(LOO_model)\n",
    "    \n",
    "    # compute the residuals\n",
    "    residual_quantiles_dict = defaultdict(list)\n",
    "    for i in train_idx:\n",
    "        df_curr = df_train[df_train.Electrode == i]\n",
    "        residual = np.abs(df_curr[\"DA\"] - LOO_model.predict(df_curr.drop(columns=[\"DA\", \"Electrode\"])))\n",
    "        for alpha, delta in alpha_delta_list: \n",
    "            residual_quantiles_dict[(alpha, delta)].append(q_plus(residual, alpha))\n",
    "\n",
    "    # compute the residual quantiles\n",
    "    q_dict = {}\n",
    "    for alpha, delta in alpha_delta_list:\n",
    "        q_dict[(alpha, delta)] = q_plus(np.array(residual_quantiles_dict[(alpha, delta)]), delta)\n",
    "\n",
    "\n",
    "    total_card_list = defaultdict(list)\n",
    "    total_covered_list = defaultdict(list)\n",
    "    total_count_list = defaultdict(list)     \n",
    "\n",
    "    test_idx = df_test[\"Electrode\"].unique()    \n",
    "    for test_idx_num in test_idx:\n",
    "        curr_df = df_test[df_test.Electrode == test_idx_num]\n",
    "        y_true = curr_df[\"DA\"]\n",
    "        # stores the predictions by the trained LOO models\n",
    "        pred_list = []\n",
    "\n",
    "        for i in range(len(models)):\n",
    "            curr_model = models[i]\n",
    "            curr_pred = curr_model.predict(curr_df.drop(columns=[\"DA\", \"Electrode\"]))\n",
    "            pred_list.append(curr_pred)\n",
    "\n",
    "        pred_min = np.min(pred_list, axis=0)\n",
    "        pred_max = np.max(pred_list, axis=0)\n",
    "\n",
    "        for alpha, delta in alpha_delta_list:\n",
    "            q = q_dict[(alpha, delta)]\n",
    "            lo, hi = pred_min - q, pred_max + q\n",
    "            hi[hi > 2000], hi[hi < 0] = 2000, 0\n",
    "            lo[lo > 2000], lo[lo < 0] = 2000, 0\n",
    "\n",
    "            # set size\n",
    "            total_card_list[(alpha, delta)].append(np.sum(hi - lo))\n",
    "            # ratio of covered samples\n",
    "            total_covered_list[(alpha, delta)].\\\n",
    "            append(np.where(np.logical_and(y_true>=lo, y_true<=hi))[0].shape[0])\n",
    "            # number of total samples\n",
    "            total_count_list[(alpha, delta)].append(y_pred.shape[0])\n",
    "\n",
    "    results_dict = {}\n",
    "    for alpha, delta in alpha_delta_list:\n",
    "        curr_total_covered_list = np.array(total_covered_list[(alpha, delta)])\n",
    "        curr_total_card_list = np.array(total_card_list[(alpha, delta)])\n",
    "        curr_total_count_list = np.array(total_count_list[(alpha, delta)])\n",
    "\n",
    "        # compute empirical delta\n",
    "        emp_delta = np.mean(curr_total_covered_list >= np.ceil((curr_total_count_list + 1) * (1 - alpha)))\n",
    "        # compute average set size\n",
    "        emp_card = np.mean(curr_total_card_list / curr_total_count_list)\n",
    "        # compute empirical alpha\n",
    "        is_valid_coverage = (curr_total_covered_list >= (1-alpha)*(1+curr_total_count_list))\n",
    "        coverage_ratio = curr_total_covered_list / curr_total_count_list\n",
    "        emp_alpha = np.mean(coverage_ratio[is_valid_coverage])\n",
    "        \n",
    "        results_dict[(alpha, delta)] = (emp_delta, emp_alpha, emp_card)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbc734",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_delta_list = []\n",
    "for alpha in np.linspace(0.02, 0.50, 30):\n",
    "    for delta in np.linspace(0.02, 0.50, 30):\n",
    "        alpha_delta_list.append((alpha, delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return RidgeCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57dff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(df, alpha_delta_list, num_experiments=20):\n",
    "    split_results_list = []\n",
    "    jackknife_results_list = []\n",
    "    \n",
    "    for j in range(num_experiments):\n",
    "        print(f\"Processing iteration {j}\")\n",
    "        \n",
    "        train_indices, test_indices = train_test_split(df[\"Electrode\"].unique(), train_size=0.34)\n",
    "        df_train = df[df.Electrode.isin(train_indices)].drop(columns = [\"Channel\", \"pH\"])\n",
    "        df_test = df[~df.Electrode.isin(train_indices)].drop(columns = [\"Channel\", \"pH\"])\n",
    "\n",
    "        # split conformal\n",
    "        split_results_list.append(split_conformal(df_train, df_test, alpha_delta_list))\n",
    "\n",
    "        # jackknife conformal\n",
    "        jackknife_results_list.append(jackknife_conformal(df_train, df_test, alpha_delta_list))\n",
    "        \n",
    "    return split_results_list, jackknife_results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b34e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element in split_results_list and jackknife_results_list is a dictionary, \n",
    "# where the keys are (alpha, delta) pairs, and the values\n",
    "# are tuples of (empirical delta, empirical alpha, average set size)\n",
    "\n",
    "split_results_list, jackknife_results_list = get_results(df, alpha_delta_list, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0a54f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
