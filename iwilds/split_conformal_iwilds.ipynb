{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75f298-a8cc-4b3f-985b-94f81241c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fa723-b59e-4737-a3aa-b2c7129be28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wilds\n",
    "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "from wilds.common.grouper import CombinatorialGrouper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe5286-c073-4583-84fe-0df0cdfd9f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed, Logger, BatchLogger, log_config, ParseKwargs, load, initialize_wandb, log_group_data, parse_bool, get_model_prefix\n",
    "from train import train, evaluate\n",
    "from algorithms.initializer import initialize_algorithm\n",
    "from transforms import initialize_transform\n",
    "from configs.utils import populate_defaults\n",
    "import configs.supported as supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ccfea-4ca7-4b3b-bbc6-defd9f6a76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import json\n",
    "from wilds.datasets.wilds_dataset import WILDSDataset\n",
    "from wilds.common.grouper import CombinatorialGrouper\n",
    "from wilds.common.metrics.all_metrics import Accuracy, Recall, F1\n",
    "from typing import Optional\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from configs.supported import process_outputs_functions, process_pseudolabels_functions\n",
    "from utils import save_model, save_pred, get_pred_prefix, get_model_prefix, collate_list, detach_and_clone, InfiniteDataIterator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbce691-f526-4d1a-a515-59a01f7d5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82944abe-c692-42da-b7ae-5ab6731709f9",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07fde8-793f-4242-991d-fd6a863cebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"/wilds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5a1f6-d331-4d78-8455-a99672f7a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Required arguments\n",
    "parser.add_argument('-d', '--dataset', choices=wilds.supported_datasets, required=True)\n",
    "parser.add_argument('--algorithm', required=True, choices=supported.algorithms)\n",
    "parser.add_argument('--root_dir', required=True,\n",
    "                    help='The directory where [dataset]/data can be found (or should be downloaded to, if it does not exist).')\n",
    "\n",
    "# Dataset\n",
    "parser.add_argument('--split_scheme', help='Identifies how the train/val/test split is constructed. Choices are dataset-specific.')\n",
    "parser.add_argument('--dataset_kwargs', nargs='*', action=ParseKwargs, default={})\n",
    "parser.add_argument('--download', default=False, type=parse_bool, const=True, nargs='?',\n",
    "                    help='If true, tries to downloads the dataset if it does not exist in root_dir.')\n",
    "parser.add_argument('--frac', type=float, default=1,\n",
    "                    help='Convenience parameter that scales all dataset splits down to the specified fraction, for development purposes. Note that this also scales the test set down, so the reported numbers are not comparable with the full test set.')\n",
    "parser.add_argument('--version', default=None, type=str)\n",
    "\n",
    "# Loaders\n",
    "parser.add_argument('--loader_kwargs', nargs='*', action=ParseKwargs, default={})\n",
    "parser.add_argument('--train_loader', choices=['standard', 'group'])\n",
    "parser.add_argument('--uniform_over_groups', type=parse_bool, const=True, nargs='?')\n",
    "parser.add_argument('--distinct_groups', type=parse_bool, const=True, nargs='?')\n",
    "parser.add_argument('--n_groups_per_batch', type=int)\n",
    "parser.add_argument('--batch_size', type=int)\n",
    "parser.add_argument('--eval_loader', choices=['standard'], default='standard')\n",
    "\n",
    "# Model\n",
    "parser.add_argument('--model', choices=supported.models)\n",
    "parser.add_argument('--model_kwargs', nargs='*', action=ParseKwargs, default={},\n",
    "    help='keyword arguments for model initialization passed as key1=value1 key2=value2')\n",
    "\n",
    "# Transforms\n",
    "parser.add_argument('--train_transform', choices=supported.transforms)\n",
    "parser.add_argument('--eval_transform', choices=supported.transforms)\n",
    "parser.add_argument('--target_resolution', nargs='+', type=int, help='The input resolution that images will be resized to before being passed into the model. For example, use --target_resolution 224 224 for a standard ResNet.')\n",
    "parser.add_argument('--resize_scale', type=float)\n",
    "parser.add_argument('--max_token_length', type=int)\n",
    "\n",
    "# Objective\n",
    "parser.add_argument('--loss_function', choices = supported.losses)\n",
    "\n",
    "# Algorithm\n",
    "parser.add_argument('--groupby_fields', nargs='+')\n",
    "parser.add_argument('--group_dro_step_size', type=float)\n",
    "parser.add_argument('--coral_penalty_weight', type=float)\n",
    "parser.add_argument('--irm_lambda', type=float)\n",
    "parser.add_argument('--irm_penalty_anneal_iters', type=int)\n",
    "parser.add_argument('--algo_log_metric')\n",
    "\n",
    "# Model selection\n",
    "parser.add_argument('--val_metric')\n",
    "parser.add_argument('--val_metric_decreasing', type=parse_bool, const=True, nargs='?')\n",
    "\n",
    "# Optimization\n",
    "parser.add_argument('--n_epochs', type=int)\n",
    "parser.add_argument('--optimizer', choices=supported.optimizers)\n",
    "parser.add_argument('--lr', type=float)\n",
    "parser.add_argument('--weight_decay', type=float)\n",
    "parser.add_argument('--max_grad_norm', type=float)\n",
    "parser.add_argument('--optimizer_kwargs', nargs='*', action=ParseKwargs, default={})\n",
    "\n",
    "# Scheduler\n",
    "parser.add_argument('--scheduler', choices=supported.schedulers)\n",
    "parser.add_argument('--scheduler_kwargs', nargs='*', action=ParseKwargs, default={})\n",
    "parser.add_argument('--scheduler_metric_split', choices=['train', 'val'], default='val')\n",
    "parser.add_argument('--scheduler_metric_name')\n",
    "\n",
    "# Evaluation\n",
    "parser.add_argument('--process_outputs_function', choices = supported.process_outputs_functions)\n",
    "parser.add_argument('--evaluate_all_splits', type=parse_bool, const=True, nargs='?', default=True)\n",
    "parser.add_argument('--eval_splits', nargs='+', default=[])\n",
    "parser.add_argument('--eval_only', type=parse_bool, const=True, nargs='?', default=False)\n",
    "parser.add_argument('--eval_epoch', default=None, type=int, help='If eval_only is set, then eval_epoch allows you to specify evaluating at a particular epoch. By default, it evaluates the best epoch by validation performance.')\n",
    "\n",
    "# Misc\n",
    "parser.add_argument('--device', type=int, default=0)\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--log_dir', default='./logs')\n",
    "parser.add_argument('--log_every', default=50, type=int)\n",
    "parser.add_argument('--save_step', type=int)\n",
    "parser.add_argument('--save_best', type=parse_bool, const=True, nargs='?', default=True)\n",
    "parser.add_argument('--save_last', type=parse_bool, const=True, nargs='?', default=True)\n",
    "parser.add_argument('--save_pred', type=parse_bool, const=True, nargs='?', default=True)\n",
    "parser.add_argument('--no_group_logging', type=parse_bool, const=True, nargs='?')\n",
    "parser.add_argument('--use_wandb', type=parse_bool, const=True, nargs='?', default=False)\n",
    "parser.add_argument('--progress_bar', type=parse_bool, const=True, nargs='?', default=False)\n",
    "parser.add_argument('--resume', type=parse_bool, const=True, nargs='?', default=False)\n",
    "parser.add_argument('--use_unlabeled_y', default=False, type=parse_bool, const=True, nargs='?', \n",
    "                    help='If true, unlabeled loaders will also the true labels for the unlabeled data. This is only available for some datasets. Used for \"fully-labeled ERM experiments\" in the paper. Correct functionality relies on CrossEntropyLoss using ignore_index=-100.')\n",
    "parser.add_argument('--additional_train_transform', choices=supported.additional_transforms, help='Optional data augmentations to layer on top of the default transforms.')\n",
    "parser.add_argument('--load_featurizer_only', default=False, type=parse_bool, const=True, nargs='?', help='If true, only loads the featurizer weights and not the classifier weights.')\n",
    "parser.add_argument('--unlabeled_loader_kwargs', nargs='*', action=ParseKwargs, default={})\n",
    "parser.add_argument('--gradient_accumulation_steps', type=int, default=1, help='Number of batches to process before stepping optimizer and schedulers. If > 1, we simulate having a larger effective batch size (though batchnorm behaves differently).')\n",
    "parser.add_argument('--pretrained_model_path', default=None, type=str, help='Specify a path to pretrained model weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188bf4d-4f76-470c-bb76-be0810042e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_parsed = [\n",
    "    '--dataset',\n",
    "    'iwildcam',\n",
    "    '--algorithm',\n",
    "    'ERM',\n",
    "    '--root_dir',\n",
    "    os.path.join(root_folder,'data'),\n",
    "    '--train_transform',\n",
    "    \"image_base\",\n",
    "    '--eval_transform',\n",
    "    \"image_base\",    \n",
    "    '--resume',\n",
    "    '--eval_only',\n",
    "    \"--save_last\",\n",
    "    \"False\",\n",
    "    '--n_epochs',\n",
    "    '5'\n",
    "]\n",
    "\n",
    "config = parser.parse_args(string_parsed)\n",
    "config = populate_defaults(config)\n",
    "config.loader_kwargs['num_workers'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364c81a-e98f-4e02-9ce4-c189ba5b07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    config.use_data_parallel = False\n",
    "    config.device = torch.device(\"cuda:\" + str(config.device))\n",
    "else:\n",
    "    config.use_data_parallel = False\n",
    "    config.device = torch.device(\"cpu\")\n",
    "\n",
    "config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a1539-4ba7-4995-a22e-830df40ffbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logs\n",
    "if os.path.exists(config.log_dir) and config.resume:\n",
    "    resume=True\n",
    "    mode='a'\n",
    "elif os.path.exists(config.log_dir) and config.eval_only:\n",
    "    resume=False\n",
    "    mode='a'\n",
    "else:\n",
    "    resume=False\n",
    "    mode='w'\n",
    "\n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.makedirs(config.log_dir)\n",
    "logger = Logger(os.path.join(config.log_dir, 'log.txt'), mode)\n",
    "\n",
    "# Record config\n",
    "log_config(config, logger)\n",
    "\n",
    "# Set random seed\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2fcf0e-7315-42ad-b1bd-335bbb3a3460",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc286b-bee3-432f-9c4a-74984cba2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(input_df, train_frac=0.8):\n",
    "    train_msk = np.random.choice(input_df.index, size = int(train_frac*(len(input_df))), replace=False)\n",
    "    input_df.loc[train_msk, 'split'] = \"train\"\n",
    "    input_df.loc[input_df.index.difference(train_msk), 'split'] = \"val\"\n",
    "    \n",
    "def q_plus(arr, alpha):\n",
    "    arr = list(arr)\n",
    "    n = len(arr)\n",
    "    idx = np.ceil((1-alpha)*(n+1)).astype(\"int\")-1\n",
    "    if idx >= n:\n",
    "        return float(\"inf\")\n",
    "    else:\n",
    "        return np.partition(arr, idx)[idx]\n",
    "\n",
    "def q_minus(arr, alpha):\n",
    "    arr = list(arr)\n",
    "    n = len(arr)\n",
    "    idx = np.floor(alpha*(n+1))-1\n",
    "    if idx < 0:\n",
    "        return -float(\"inf\")\n",
    "    else:\n",
    "        return np.partition(arr, idx)[idx]\n",
    "    \n",
    "# Compute tau\n",
    "def split_conformal_compute_tau(total_res, alpha, delta):\n",
    "    S_list = []\n",
    "    for res in total_res:\n",
    "        S_list.append(q_plus(res, alpha))\n",
    "    return q_plus(np.array(S_list), delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8cffb1-8c28-4065-ace9-686a2deddd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_delta_list = []\n",
    "for alpha in np.linspace(0.02, 0.88, 50):\n",
    "    for delta in np.linspace(0.02, 0.88, 50):\n",
    "        alpha_delta_list.append((alpha, delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a3ab0-4550-48ed-9202-8174c5172896",
   "metadata": {},
   "source": [
    "# Filter & Split Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb4b2b-75bf-48e1-b74a-1891c14d1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct LOO datasets\n",
    "df_filename = config.root_dir + \"/iwildcam_v2.0/metadata.csv\"\n",
    "df = pd.read_csv(df_filename)\n",
    "\n",
    "# remove domains with <= 100 samples\n",
    "sample_threshold = 100\n",
    "sample_count_ser = df.groupby(['location_remapped'])['split'].count()\n",
    "filtered_ser = sample_count_ser[sample_count_ser > sample_threshold]\n",
    "df = df[df['location_remapped'].isin(filtered_ser.index)]\n",
    "\n",
    "# remove categories that appear in <= 5% domains\n",
    "domain_threshold = int(0.05 * len(df['location_remapped'].unique()))\n",
    "print(f\"domain_threshold: {domain_threshold}\")\n",
    "domain_count_ser = df.groupby(\"category_id\")[\"location_remapped\"].nunique()\n",
    "filtered_category_ser = domain_count_ser[domain_count_ser > domain_threshold]\n",
    "df = df[df[\"category_id\"].isin(filtered_category_ser.index)]\n",
    "\n",
    "unique_domains = df['location_remapped'].unique()\n",
    "num_domains = len(unique_domains)\n",
    "print(\"Number of unique domains: \", num_domains)\n",
    "print(\"Number of unique categories: \", df.category_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664dc287-bc61-4ac2-8f2d-a80e5291b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap category ids\n",
    "old_cates = df.category_id.unique()\n",
    "cate_map = {cate:idx for idx, cate in enumerate(old_cates)}\n",
    "df['category_id'] = df['category_id'].map(cate_map)\n",
    "df['y'] = df['category_id']\n",
    "num_cate_total = df['category_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f35c4-2b49-406b-bc7c-37b3b8c428e5",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb2b62-f62b-4215-ab48-3569d582bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IWildCamDatasetModified(WILDSDataset):\n",
    "    _dataset_name = 'iwildcam'\n",
    "    _versions_dict = {\n",
    "        '2.0': {\n",
    "            'download_url': 'https://worksheets.codalab.org/rest/bundles/0x6313da2b204647e79a14b468131fcd64/contents/blob/',\n",
    "            'compressed_size': 11_957_420_032}}\n",
    "\n",
    "\n",
    "    def __init__(self, version=None, root_dir='data', download=False, split_scheme='official', metadata_filename = 'metadata.csv', num_classes = None):\n",
    "        self._version = version\n",
    "        self._split_scheme = split_scheme\n",
    "        if self._split_scheme != 'official':\n",
    "            raise ValueError(f'Split scheme {self._split_scheme} not recognized')\n",
    "\n",
    "        # path\n",
    "        self._data_dir = Path(self.initialize_data_dir(root_dir, download))\n",
    "\n",
    "        # Load splits\n",
    "        df = pd.read_csv(self._data_dir / metadata_filename)\n",
    "\n",
    "        # Splits\n",
    "        self._split_dict = {'train': 0, 'val': 1, 'test': 2, 'id_val': 3, 'id_test': 4}\n",
    "        self._split_names = {'train': 'Train', 'val': 'Validation (OOD/Trans)',\n",
    "                                'test': 'Test (OOD/Trans)', 'id_val': 'Validation (ID/Cis)',\n",
    "                                'id_test': 'Test (ID/Cis)'}\n",
    "\n",
    "        df['split_id'] = df['split'].apply(lambda x: self._split_dict[x])\n",
    "        self._split_array = df['split_id'].values\n",
    "\n",
    "        # Filenames\n",
    "        self._input_array = df['filename'].values\n",
    "\n",
    "        # Labels\n",
    "        self._y_array = torch.tensor(df['y'].values)\n",
    "        if num_classes is None:\n",
    "            self._n_classes = max(df['y']) + 1\n",
    "        else:\n",
    "            self._n_classes = num_classes\n",
    "        self._y_size = 1\n",
    "        # assert len(np.unique(df['y'])) == self._n_classes\n",
    "\n",
    "        # Location/group info\n",
    "        n_groups = max(df['location_remapped']) + 1\n",
    "        self._n_groups = n_groups\n",
    "        # assert len(np.unique(df['location_remapped'])) == self._n_groups\n",
    "\n",
    "        # Sequence info\n",
    "        n_sequences = max(df['sequence_remapped']) + 1\n",
    "        self._n_sequences = n_sequences\n",
    "        # assert len(np.unique(df['sequence_remapped'])) == self._n_sequences\n",
    "\n",
    "        # Extract datetime subcomponents and include in metadata\n",
    "        df['datetime_obj'] = df['datetime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f'))\n",
    "        df['year'] = df['datetime_obj'].apply(lambda x: int(x.year))\n",
    "        df['month'] = df['datetime_obj'].apply(lambda x: int(x.month))\n",
    "        df['day'] = df['datetime_obj'].apply(lambda x: int(x.day))\n",
    "        df['hour'] = df['datetime_obj'].apply(lambda x: int(x.hour))\n",
    "        df['minute'] = df['datetime_obj'].apply(lambda x: int(x.minute))\n",
    "        df['second'] = df['datetime_obj'].apply(lambda x: int(x.second))\n",
    "\n",
    "        self._metadata_array = torch.tensor(np.stack([df['location_remapped'].values,\n",
    "                            df['sequence_remapped'].values,\n",
    "                            df['year'].values, df['month'].values, df['day'].values,\n",
    "                            df['hour'].values, df['minute'].values, df['second'].values,\n",
    "                            self.y_array], axis=1))\n",
    "        self._metadata_fields = ['location', 'sequence', 'year', 'month', 'day', 'hour', 'minute', 'second', 'y']\n",
    "\n",
    "        # eval grouper\n",
    "        self._eval_grouper = CombinatorialGrouper(\n",
    "            dataset=self,\n",
    "            groupby_fields=None)\n",
    "\n",
    "        super().__init__(root_dir, download, split_scheme)\n",
    "\n",
    "    def eval(self, y_pred, y_true, metadata, prediction_fn=None):\n",
    "        \"\"\"\n",
    "        Computes all evaluation metrics.\n",
    "        Args:\n",
    "            - y_pred (Tensor): Predictions from a model. By default, they are predicted labels (LongTensor).\n",
    "                               But they can also be other model outputs such that prediction_fn(y_pred)\n",
    "                               are predicted labels.\n",
    "            - y_true (LongTensor): Ground-truth labels\n",
    "            - metadata (Tensor): Metadata\n",
    "            - prediction_fn (function): A function that turns y_pred into predicted labels\n",
    "        Output:\n",
    "            - results (dictionary): Dictionary of evaluation metrics\n",
    "            - results_str (str): String summarizing the evaluation metrics\n",
    "        \"\"\"\n",
    "        metrics = [\n",
    "            Accuracy(prediction_fn=prediction_fn),\n",
    "            Recall(prediction_fn=prediction_fn, average='macro'),\n",
    "            F1(prediction_fn=prediction_fn, average='macro'),\n",
    "        ]\n",
    "\n",
    "        results = {}\n",
    "        for i in range(len(metrics)):\n",
    "            results.update({\n",
    "                **metrics[i].compute(y_pred, y_true),\n",
    "                        })\n",
    "        results_str = (\n",
    "            f\"Average acc: {results[metrics[0].agg_metric_field]:.3f}\\n\"\n",
    "            f\"Recall macro: {results[metrics[1].agg_metric_field]:.3f}\\n\"\n",
    "            f\"F1 macro: {results[metrics[2].agg_metric_field]:.3f}\\n\"\n",
    "        )\n",
    "        return results, results_str\n",
    "\n",
    "    def get_input(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - idx (int): Index of a data point\n",
    "        Output:\n",
    "            - x (Tensor): Input features of the idx-th data point\n",
    "        \"\"\"\n",
    "\n",
    "        # All images are in the train folder\n",
    "        img_path = self.data_dir / 'train' / self._input_array[idx]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde8344-d651-4f5a-b3ce-8a51b5b19636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modified_dataset(dataset: str, version: Optional[str] = None, unlabeled: bool = False, metadata_filename = 'pretrain_metadata.csv', num_classes = None, **dataset_kwargs):\n",
    "    \"\"\"\n",
    "    Returns the appropriate WILDS dataset class.\n",
    "    Input:\n",
    "        dataset (str): Name of the dataset\n",
    "        version (Union[str, None]): Dataset version number, e.g., '1.0'.\n",
    "                                    Defaults to the latest version.\n",
    "        unlabeled (bool): If true, use the unlabeled version of the dataset.\n",
    "        dataset_kwargs: Other keyword arguments to pass to the dataset constructors.\n",
    "    Output:\n",
    "        The specified WILDSDataset class.\n",
    "    \"\"\"\n",
    "    if version is not None:\n",
    "        version = str(version)\n",
    "\n",
    "    if dataset not in wilds.supported_datasets:\n",
    "        raise ValueError(f'The dataset {dataset} is not recognized. Must be one of {wilds.supported_datasets}.')\n",
    "\n",
    "    if unlabeled and dataset not in wilds.unlabeled_datasets:\n",
    "        raise ValueError(f'Unlabeled data is not available for {dataset}. Must be one of {wilds.unlabeled_datasets}.')\n",
    "\n",
    "    if dataset == 'iwildcam':\n",
    "        if unlabeled:\n",
    "            print(\"unlabeled\")\n",
    "            from wilds.datasets.unlabeled.iwildcam_unlabeled_dataset import IWildCamUnlabeledDataset\n",
    "            return IWildCamUnlabeledDataset(version=version, **dataset_kwargs)\n",
    "        else:\n",
    "            if version == '1.0':\n",
    "                from wilds.datasets.archive.iwildcam_v1_0_dataset import IWildCamDataset\n",
    "            else:\n",
    "                # from wilds.datasets.iwildcam_dataset import IWildCamDataset # type:ignore\n",
    "                return IWildCamDatasetModified(version=version,\\\n",
    "                       metadata_filename = metadata_filename, \\\n",
    "                       num_classes = num_classes, **dataset_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cfbad2-a72f-4a34-bd28-321667a93309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(data_filename):\n",
    "    full_dataset = get_modified_dataset(\n",
    "        dataset=config.dataset,\n",
    "        version=config.version,\n",
    "        root_dir=config.root_dir,\n",
    "        download=config.download,\n",
    "        split_scheme=config.split_scheme,\n",
    "        metadata_filename = data_filename,\n",
    "        num_classes = num_cate_total,\n",
    "        **config.dataset_kwargs\n",
    "    )\n",
    "    \n",
    "    train_transform = initialize_transform(\n",
    "        transform_name=config.train_transform,\n",
    "        config=config,\n",
    "        dataset=full_dataset,\n",
    "        is_training = True)\n",
    "    eval_transform = initialize_transform(\n",
    "        transform_name=config.eval_transform,\n",
    "        config=config,\n",
    "        dataset=full_dataset,\n",
    "        is_training = False)\n",
    "\n",
    "    train_grouper = CombinatorialGrouper(\n",
    "        dataset=full_dataset,\n",
    "        groupby_fields=None)\n",
    "\n",
    "    \n",
    "    datasets = defaultdict(dict)\n",
    "    for split in full_dataset.split_dict.keys():\n",
    "        if split=='train':\n",
    "            transform = train_transform\n",
    "            verbose = True\n",
    "        elif split == 'val':\n",
    "            transform = eval_transform\n",
    "            verbose = True\n",
    "        else:\n",
    "            transform = eval_transform\n",
    "            verbose = False\n",
    "        # Get subset\n",
    "        datasets[split]['dataset'] = full_dataset.get_subset(\n",
    "            split,\n",
    "            frac = config.frac,\n",
    "            transform=transform)\n",
    "\n",
    "        if split == 'train':\n",
    "            datasets[split]['loader'] = get_train_loader(\n",
    "                loader=config.train_loader,\n",
    "                dataset=datasets[split]['dataset'],\n",
    "                batch_size=config.batch_size,\n",
    "                uniform_over_groups=config.uniform_over_groups,\n",
    "                grouper=train_grouper,\n",
    "                distinct_groups=config.distinct_groups,\n",
    "                n_groups_per_batch=config.n_groups_per_batch,\n",
    "                **config.loader_kwargs)\n",
    "        else:\n",
    "            datasets[split]['loader'] = get_eval_loader(\n",
    "                loader=config.eval_loader,\n",
    "                dataset=datasets[split]['dataset'],\n",
    "                grouper=train_grouper,\n",
    "                batch_size=config.batch_size,\n",
    "                **config.loader_kwargs)\n",
    "\n",
    "        # Set fields\n",
    "        datasets[split]['split'] = split\n",
    "        datasets[split]['name'] = full_dataset.split_names[split]\n",
    "        datasets[split]['verbose'] = verbose\n",
    "\n",
    "        # Loggers\n",
    "        datasets[split]['eval_logger'] = BatchLogger(\n",
    "            os.path.join(config.log_dir, f'{split}_eval.csv'), mode=mode, use_wandb=(config.use_wandb and verbose))\n",
    "        datasets[split]['algo_logger'] = BatchLogger(\n",
    "            os.path.join(config.log_dir, f'{split}_algo.csv'), mode=mode, use_wandb=(config.use_wandb and verbose))\n",
    "\n",
    "        if config.use_wandb:\n",
    "            initialize_wandb(config)\n",
    "\n",
    "    # Logging dataset info\n",
    "    # Show class breakdown if feasible\n",
    "    if config.no_group_logging and full_dataset.is_classification and full_dataset.y_size==1 and full_dataset.n_classes <= 10:\n",
    "        log_grouper = CombinatorialGrouper(\n",
    "            dataset=full_dataset,\n",
    "            groupby_fields=None)\n",
    "    elif config.no_group_logging:\n",
    "        log_grouper = None\n",
    "    else:\n",
    "        log_grouper = train_grouper\n",
    "    log_group_data(datasets, log_grouper, logger)\n",
    "    \n",
    "    return datasets, train_grouper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f37f7-e075-407b-ba22-e291a2c2a0d1",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983a6bf-1694-4407-8fc1-3366ca09faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(y_true, num_labels = num_cate_total):\n",
    "    n = y_true.shape[0]\n",
    "    res = np.zeros([n, num_labels])\n",
    "    res[np.arange(n), y_true] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d82848-68ea-44c9-9a13-cb7e6399c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(algorithm, dataset, general_logger, epoch, config, train, unlabeled_dataset=None):\n",
    "    if dataset['verbose']:\n",
    "        general_logger.write(f\"\\n{dataset['name']}:\\n\")\n",
    "\n",
    "    if train:\n",
    "        algorithm.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        algorithm.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "    # Not preallocating memory is slower\n",
    "    # but makes it easier to handle different types of data loaders\n",
    "    # (which might not return exactly the same number of examples per epoch)\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    epoch_metadata = []\n",
    "\n",
    "    # Assert that data loaders are defined for the datasets\n",
    "    assert 'loader' in dataset, \"A data loader must be defined for the dataset.\"\n",
    "    if unlabeled_dataset:\n",
    "        assert 'loader' in unlabeled_dataset, \"A data loader must be defined for the dataset.\"\n",
    "\n",
    "    batches = dataset['loader']\n",
    "    if config.progress_bar:\n",
    "        batches = tqdm(batches)\n",
    "    last_batch_idx = len(batches)-1\n",
    "    \n",
    "    if unlabeled_dataset:\n",
    "        unlabeled_data_iterator = InfiniteDataIterator(unlabeled_dataset['loader'])\n",
    "\n",
    "    # Using enumerate(iterator) can sometimes leak memory in some environments (!)\n",
    "    # so we manually increment batch_idx\n",
    "    batch_idx = 0\n",
    "    for labeled_batch in batches:\n",
    "        if train:\n",
    "            if unlabeled_dataset:\n",
    "                unlabeled_batch = next(unlabeled_data_iterator)\n",
    "                batch_results = algorithm.update(labeled_batch, unlabeled_batch, is_epoch_end=(batch_idx==last_batch_idx))\n",
    "            else:\n",
    "                batch_results = algorithm.update(labeled_batch, is_epoch_end=(batch_idx==last_batch_idx))\n",
    "        else:\n",
    "            batch_results = algorithm.evaluate(labeled_batch)\n",
    "\n",
    "        # These tensors are already detached, but we need to clone them again\n",
    "        # Otherwise they don't get garbage collected properly in some versions\n",
    "        # The extra detach is just for safety\n",
    "        # (they should already be detached in batch_results)\n",
    "        epoch_y_true.append(detach_and_clone(batch_results['y_true']))\n",
    "        y_pred = detach_and_clone(batch_results['y_pred'])\n",
    "        if config.process_outputs_function is not None:\n",
    "            y_pred = process_outputs_functions[config.process_outputs_function](y_pred)\n",
    "        epoch_y_pred.append(y_pred)\n",
    "        epoch_metadata.append(detach_and_clone(batch_results['metadata']))\n",
    "\n",
    "        if train: \n",
    "            effective_batch_idx = (batch_idx + 1) / config.gradient_accumulation_steps\n",
    "        else: \n",
    "            effective_batch_idx = batch_idx + 1\n",
    "\n",
    "        if train and effective_batch_idx % config.log_every==0:\n",
    "            log_results(algorithm, dataset, general_logger, epoch, math.ceil(effective_batch_idx))\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "    epoch_y_pred = collate_list(epoch_y_pred)\n",
    "    epoch_y_true = collate_list(epoch_y_true)\n",
    "    epoch_metadata = collate_list(epoch_metadata)\n",
    "\n",
    "    results, results_str = dataset['dataset'].eval(\n",
    "        epoch_y_pred,\n",
    "        epoch_y_true,\n",
    "        epoch_metadata)\n",
    "\n",
    "    if config.scheduler_metric_split==dataset['split']:\n",
    "        algorithm.step_schedulers(\n",
    "            is_epoch=True,\n",
    "            metrics=results,\n",
    "            log_access=(not train))\n",
    "\n",
    "    # log after updating the scheduler in case it needs to access the internal logs\n",
    "    log_results(algorithm, dataset, general_logger, epoch, math.ceil(effective_batch_idx))\n",
    "\n",
    "    results['epoch'] = epoch\n",
    "    dataset['eval_logger'].log(results)\n",
    "    if dataset['verbose']:\n",
    "        general_logger.write('Epoch eval:\\n')\n",
    "        general_logger.write(results_str)\n",
    "\n",
    "    return results, epoch_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bac38-61f9-4e5b-b583-7be88811af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(algorithm, datasets, general_logger, config, epoch_offset, best_val_metric, domain_num, unlabeled_dataset=None, validation_threshold=0.90):\n",
    "    \"\"\"\n",
    "    Train loop that, each epoch:\n",
    "        - Steps an algorithm on the datasets['train'] split and the unlabeled split\n",
    "        - Evaluates the algorithm on the datasets['val'] split\n",
    "        - Saves models / preds with frequency according to the configs\n",
    "        - Evaluates on any other specified splits in the configs\n",
    "    Assumes that the datasets dict contains labeled data.\n",
    "    \"\"\"\n",
    "    \n",
    "    early_stop_count = 0\n",
    "    for epoch in range(epoch_offset, config.n_epochs):\n",
    "        general_logger.write('\\nEpoch [%d]:\\n' % epoch)\n",
    "\n",
    "        # First run training\n",
    "        run_epoch(algorithm, datasets['train'], general_logger, epoch, config, train=True, unlabeled_dataset=unlabeled_dataset)\n",
    "\n",
    "        # Then run val\n",
    "        val_results, y_pred = run_epoch(algorithm, datasets['val'], general_logger, epoch, config, train=False)\n",
    "        curr_val_metric = val_results[config.val_metric]\n",
    "        # general_logger.write(f'Validation {config.val_metric}: {curr_val_metric:.3f}\\n')\n",
    "\n",
    "        if best_val_metric is None:\n",
    "            is_best = True\n",
    "        else:\n",
    "            if config.val_metric_decreasing:\n",
    "                is_best = curr_val_metric < best_val_metric\n",
    "            else:\n",
    "                is_best = curr_val_metric > best_val_metric\n",
    "        if is_best:\n",
    "            best_val_metric = curr_val_metric\n",
    "            # general_logger.write(f'Epoch {epoch} has the best validation performance so far.\\n')\n",
    "\n",
    "        save_model_if_needed(algorithm, datasets['val'], epoch, config, is_best, best_val_metric, domain_num)\n",
    "        save_pred_if_needed(y_pred, datasets['val'], epoch, config, is_best)\n",
    "\n",
    "        general_logger.write('\\n')\n",
    "        \n",
    "        if val_results[\"acc_avg\"] > validation_threshold:\n",
    "            early_stop_count += 1\n",
    "            print(f\"early_stop_count: {early_stop_count}\")\n",
    "            if early_stop_count >= 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb497e1-e208-4c60-992c-317773cff420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(algorithm, datasets, epoch, general_logger, config, is_best):\n",
    "    algorithm.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    for split, dataset in datasets.items():\n",
    "        if (not config.evaluate_all_splits) and (split not in config.eval_splits):\n",
    "            continue\n",
    "        epoch_y_true = []\n",
    "        epoch_y_pred = []\n",
    "        epoch_metadata = []\n",
    "        iterator = tqdm(dataset['loader']) if config.progress_bar else dataset['loader']\n",
    "        for batch in iterator:\n",
    "            batch_results = algorithm.evaluate(batch)\n",
    "            epoch_y_true.append(detach_and_clone(batch_results['y_true']))\n",
    "            y_pred = detach_and_clone(batch_results['y_pred'])\n",
    "            if config.process_outputs_function is not None:\n",
    "                y_pred = process_outputs_functions[config.process_outputs_function](y_pred)\n",
    "            epoch_y_pred.append(y_pred)\n",
    "            epoch_metadata.append(detach_and_clone(batch_results['metadata']))\n",
    "\n",
    "        epoch_y_pred = collate_list(epoch_y_pred)\n",
    "        epoch_y_true = collate_list(epoch_y_true)\n",
    "        epoch_metadata = collate_list(epoch_metadata)\n",
    "        ear, results_str = dataset['dataset'].eval(\n",
    "            epoch_y_pred,\n",
    "            epoch_y_true,\n",
    "            epoch_metadata)\n",
    "\n",
    "        results['epoch'] = epoch\n",
    "        dataset['eval_logger'].log(results)\n",
    "        general_logger.write(f'Eval split {split} at epoch {epoch}:\\n')\n",
    "        general_logger.write(results_str)\n",
    "\n",
    "        # Skip saving train preds, since the train loader generally shuffles the data\n",
    "        if split != 'train':\n",
    "            save_pred_if_needed(epoch_y_pred, dataset, epoch, config, is_best, force_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165ab1bc-e6e1-4bb1-9461-766f1e0c32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(algorithm, batches):\n",
    "    res = []\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    epoch_metadata = []\n",
    "\n",
    "    algorithm.eval()\n",
    "    for labeled_batch in batches:\n",
    "        batch_results = algorithm.evaluate(labeled_batch)\n",
    "        y_pred = detach_and_clone(batch_results['y_pred'])\n",
    "\n",
    "        epoch_y_true.append(detach_and_clone(batch_results['y_true']))\n",
    "        epoch_y_pred.append(y_pred)\n",
    "\n",
    "    epoch_y_pred = collate_list(epoch_y_pred)\n",
    "    epoch_y_true = collate_list(epoch_y_true)\n",
    "    n, p = epoch_y_pred.shape\n",
    "    loss = -np.log(softmax(epoch_y_pred, axis=1))[np.arange(n), epoch_y_true]\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3788c9a-06fd-4c16-8975-35665b1489da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_if_needed(algorithm, dataset, epoch, config, is_best, best_val_metric, domain_num):\n",
    "    prefix = get_model_prefix(dataset, config) + str(domain_num) + \"_\"\n",
    "    if config.save_step is not None and (epoch + 1) % config.save_step == 0:\n",
    "        save_model(algorithm, epoch, best_val_metric, prefix + f'epoch:{epoch}_model.pth')\n",
    "    if config.save_last:\n",
    "        save_model(algorithm, epoch, best_val_metric, prefix + 'epoch:last_model.pth')\n",
    "    if config.save_best and is_best:\n",
    "        save_model(algorithm, epoch, best_val_metric, prefix + 'epoch:best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb16e6-6385-4d75-87b7-aa74901656d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_results(algorithm, dataset, general_logger, epoch, effective_batch_idx):\n",
    "    if algorithm.has_log:\n",
    "        log = algorithm.get_log()\n",
    "        log['epoch'] = epoch\n",
    "        log['batch'] = effective_batch_idx\n",
    "        dataset['algo_logger'].log(log)\n",
    "        if dataset['verbose']:\n",
    "            general_logger.write(algorithm.get_pretty_log_str())\n",
    "        algorithm.reset_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c1201-5fe7-4db8-bc1e-7ba1935692a2",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122149d-3cb6-476d-8cd2-704464321b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_predictions(model, loader, config):\n",
    "    \"\"\"\n",
    "    Simple inference loop that performs inference using a model (not algorithm) and returns model outputs.\n",
    "    Compatible with both labeled and unlabeled WILDS datasets.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    iterator = tqdm(loader) if config.progress_bar else loader\n",
    "    for batch in iterator:\n",
    "        x = batch[0]\n",
    "        x = x.to(config.device)\n",
    "        with torch.no_grad(): \n",
    "            output = model(x)\n",
    "            if not config.soft_pseudolabels and config.process_pseudolabels_function is not None:\n",
    "                _, output, _, _ = process_pseudolabels_functions[config.process_pseudolabels_function](\n",
    "                    output,\n",
    "                    confidence_threshold=config.self_training_threshold if config.dataset == 'globalwheat' else 0\n",
    "                )\n",
    "            elif config.soft_pseudolabels:\n",
    "                output = torch.nn.functional.softmax(output, dim=1)\n",
    "        if isinstance(output, list):\n",
    "            y_pred.extend(detach_and_clone(output))\n",
    "        else:\n",
    "            y_pred.append(detach_and_clone(output))\n",
    "\n",
    "    return torch.cat(y_pred, 0) if torch.is_tensor(y_pred[0]) else y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aab038-8e51-434f-b633-69f999c15101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred_if_needed(y_pred, dataset, epoch, config, is_best, force_save=False):\n",
    "    if config.save_pred:\n",
    "        prefix = get_pred_prefix(dataset, config)\n",
    "        if force_save or (config.save_step is not None and (epoch + 1) % config.save_step == 0):\n",
    "            save_pred(y_pred, prefix + f'epoch:{epoch}_pred')\n",
    "        if (not force_save) and config.save_last:\n",
    "            save_pred(y_pred, prefix + f'epoch:last_pred')\n",
    "        if config.save_best and is_best:\n",
    "            save_pred(y_pred, prefix + f'epoch:best_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ad79b-defc-4e05-b4cd-ff8e63c9025c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "091b9e71-66b8-4078-9510-7cab51ab389c",
   "metadata": {},
   "source": [
    "# Conformal Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5508bec-5398-42d1-a7a1-c7604af0bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use part of the training data to train a model\n",
    "def train_D1():\n",
    "    datasets, train_grouper = load_datasets(\"split_data/D1_metadata.csv\")\n",
    "\n",
    "    ## Initialize algorithm\n",
    "    algorithm = initialize_algorithm(\n",
    "        config=config,\n",
    "        datasets=datasets,\n",
    "        train_grouper=train_grouper)\n",
    "    \n",
    "    resume_success = False\n",
    "    if resume_success == False:\n",
    "        epoch_offset=0\n",
    "        best_val_metric=None\n",
    "\n",
    "    train_model(algorithm=algorithm,\n",
    "          datasets=datasets,\n",
    "          general_logger=logger,\n",
    "          config=config,\n",
    "          epoch_offset=epoch_offset,\n",
    "          best_val_metric=best_val_metric,\n",
    "          domain_num = \"D1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2c9bd-e020-4a1c-8b20-15edb54103f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 50\n",
    "num_ID = 50\n",
    "num_OOD = num_domains - num_ID\n",
    "model_save_path = f\"/wilds/examples/logs/iwildcam_seed:0_D1_epoch:best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afbf11-411e-41b9-a964-b490aa190912",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "emp_alpha_res_list, emp_delta_res_list, emp_card_res_list = [], [], []\n",
    "\n",
    "for _ in range(num_experiments):\n",
    "    # randomly split data into two datasets\n",
    "    permutation_idx = np.random.permutation(num_domains)\n",
    "    ID_idx = unique_domains[permutation_idx[:num_ID]]\n",
    "    OOD_idx = unique_domains[permutation_idx[num_ID:]]\n",
    "\n",
    "    for i in ID_idx:\n",
    "        domain_df = df[df['location_remapped'] == i]\n",
    "        split_train_test(domain_df, train_frac=1)\n",
    "        domain_df.to_csv(config.root_dir + f\"/iwildcam_v2.0/split_data/ID_{i}_metadata.csv\")\n",
    "\n",
    "    ID_df = df[df['location_remapped'].isin(ID_idx)]\n",
    "    split_train_test(ID_df, train_frac=0.7)\n",
    "    ID_df.to_csv(config.root_dir + f\"/iwildcam_v2.0/split_data/total_ID_metadata.csv\")\n",
    "\n",
    "    OOD_df = df[df['location_remapped'].isin(OOD_idx)]\n",
    "    split_train_test(OOD_df, train_frac=1)\n",
    "    OOD_df.to_csv(config.root_dir + f\"/iwildcam_v2.0/split_data/total_OOD_metadata.csv\")\n",
    "\n",
    "    total_id_df = pd.read_csv(config.root_dir + \"/iwildcam_v2.0/split_data/total_ID_metadata.csv\")\n",
    "    ID_idx = total_id_df.location_remapped.unique()\n",
    "\n",
    "    # Split conformal algo\n",
    "    id_filename = config.root_dir + f\"/iwildcam_v2.0/split_data/total_ID_metadata.csv\"\n",
    "    ID_df = pd.read_csv(id_filename)\n",
    "    ID_idx = ID_df['location_remapped'].unique()\n",
    "    train_train_idx, train_val_idx = train_test_split(ID_idx, test_size=0.5)\n",
    "\n",
    "    # Train on D1\n",
    "    D1_df = df[df['location_remapped'].isin(train_train_idx)]\n",
    "    split_train_test(D1_df)\n",
    "    D1_df.to_csv(config.root_dir + f\"/iwildcam_v2.0/split_data/D1_metadata.csv\")\n",
    "    train_D1()\n",
    "    \n",
    "    # Evaluate on D2\n",
    "    datasets, train_grouper = load_datasets(\"split_data/D1_metadata.csv\")\n",
    "    algorithm = initialize_algorithm(\n",
    "        config=config,\n",
    "        datasets=datasets,\n",
    "        train_grouper=train_grouper)\n",
    "\n",
    "    load(algorithm, model_save_path, device=config.device) \n",
    "    algorithm.eval()\n",
    "\n",
    "    total_train_res = []\n",
    "    for domain_num in train_val_idx:\n",
    "        LOO_datasets, LOO_train_grouper = load_datasets(f'split_data/ID_{domain_num}_metadata.csv')\n",
    "        batches = LOO_datasets['train']['loader']\n",
    "        train_res = get_residuals(algorithm, batches)\n",
    "        total_train_res.append(train_res)\n",
    "    total_train_res = np.array(total_train_res)\n",
    "    \n",
    "    # Test on holdout data\n",
    "    total_count_list, total_cover_list, total_card_list =\\\n",
    "    defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "\n",
    "    lee_total_count_list, lee_total_cover_list, lee_total_card_list =\\\n",
    "    defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "\n",
    "    for domain in OOD_df['location_remapped'].unique():\n",
    "        print(f\"Processing domain {domain}\")\n",
    "        domain_df = OOD_df[OOD_df['location_remapped'] == domain]\n",
    "        split_train_test(domain_df, train_frac=1)\n",
    "        domain_df.to_csv(config.root_dir + f\"/iwildcam_v2.0/split_data/OOD_{domain}_metadata.csv\")\n",
    "\n",
    "        datasets, train_grouper = load_datasets(config.root_dir + f\"/iwildcam_v2.0/split_data/OOD_{domain}_metadata.csv\")\n",
    "        batches = datasets['train']['loader']\n",
    "        curr_train_res = get_residuals(algorithm, batches)\n",
    "\n",
    "        datasets, train_grouper = load_datasets(config.root_dir + f\"/iwildcam_v2.0/split_data/OOD_{domain}_metadata.csv\")\n",
    "        batches = datasets['train']['loader']\n",
    "\n",
    "        # for each sample, evaluate\n",
    "        total_count = defaultdict(lambda: 0)\n",
    "        total_cover = defaultdict(lambda: 0)\n",
    "        total_card = defaultdict(lambda: 0)\n",
    "        \n",
    "        # read stored residual quantiles\n",
    "        taus_dict = {}\n",
    "        for (alpha, delta) in alpha_delta_list:\n",
    "            taus_dict[(alpha, delta)] = split_conformal_compute_tau(total_train_res, alpha, delta)\n",
    "\n",
    "        for labeled_batch in batches:\n",
    "            x,y,_ = labeled_batch\n",
    "            x = x.to(algorithm.device)\n",
    "\n",
    "            y_pred = algorithm.model(x)\n",
    "            sm = torch.nn.Softmax()\n",
    "            loss_val = -torch.log(sm(y_pred)).cpu().detach().numpy()\n",
    "\n",
    "            for (alpha, delta) in alpha_delta_list:\n",
    "                tau = taus_dict[(alpha, delta)]\n",
    "                total_count[(alpha, delta)] += y_pred.shape[0]\n",
    "                total_card[(alpha, delta)] += np.sum(loss_val<= tau)\n",
    "                total_cover[(alpha, delta)] += np.sum(loss_val[np.arange(len(loss_val)), np.array(y)] <= tau)\n",
    "        \n",
    "        for (alpha, delta) in alpha_delta_list:\n",
    "            total_count_list[(alpha, delta)].append(total_count[(alpha, delta)])\n",
    "            total_cover_list[(alpha, delta)].append(total_cover[(alpha, delta)])\n",
    "            total_card_list[(alpha, delta)].append(total_card[(alpha, delta)])\n",
    "\n",
    "    # analyze methods' performance\n",
    "    emp_alpha, emp_delta, emp_card = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "    for (alpha, delta) in alpha_delta_list:\n",
    "        curr_total_cover_list = np.array(total_cover_list[(alpha, delta)])\n",
    "        curr_total_card_list = np.array(total_card_list[(alpha, delta)])\n",
    "        curr_total_count_list = np.array(total_count_list[(alpha, delta)])\n",
    "        \n",
    "        emp_card[(alpha, delta)] = np.mean(curr_total_card_list / curr_total_count_list)\n",
    "        emp_delta[(alpha, delta)] = np.mean(curr_total_cover_list >= (1-alpha)*(1+curr_total_count_list))\n",
    "        is_valid_coverage = (curr_total_cover_list >= (1-alpha)*(1+curr_total_count_list))\n",
    "        emp_alpha_all = curr_total_cover_list / curr_total_count_list\n",
    "        emp_alpha[(alpha, delta)] = np.mean(emp_alpha_all[is_valid_coverage])\n",
    "    \n",
    "    # stores the empirical alpha values\n",
    "    emp_alpha_res_list.append(emp_alpha)\n",
    "    # stores the empirical delta values\n",
    "    emp_delta_res_list.append(emp_delta)\n",
    "    # stores the average set lengths\n",
    "    emp_card_res_list.append(emp_card)\n",
    "\n",
    "    res_dict = {\"emp_alpha_res_list\": emp_alpha_res_list,\\\n",
    "               \"emp_delta_res_list\": emp_delta_res_list,\\\n",
    "                \"emp_card_res_list\": emp_card_res_list\n",
    "               }\n",
    "    with open(f'split_conformal_iwilds.pickle', 'wb') as handle:\n",
    "        pickle.dump(res_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5e2b2-2a37-40d7-83bc-5ef2c2f4cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove name\n",
    "# change frac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-kj_tf_env2]",
   "language": "python",
   "name": "conda-env-.conda-kj_tf_env2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
